{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31184627",
   "metadata": {},
   "source": [
    "Cross-validation is a statistical method used to estimate the performance of machine learning models. It is a method for assessing how the results of a statistical analysis will generalize to an independent data set. Cross-validation is a technique for evaluating ML models by training several ML models on subsets of the available input data and evaluating them on the complementary subset of the data. Use cross-validation to detect overfitting, ie, failing to generalize a pattern."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9576384",
   "metadata": {},
   "source": [
    "#### How does it tackle the problem of overfitting?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c494925",
   "metadata": {},
   "source": [
    "In Cross-Validation, we use our initial training data to generate multiple mini train-test splits. Use these splits to tune your model. For example in standard k-fold cross-validation, we partition the data into k subsets. Then, we iteratively train the algorithm on k-1 subsets while using the remaining subset as the test set. In this way, we can test our model on completely unseen data. In this notebook, you can read about the 7 most commonly used cross-validation techniques along with their pros and cons. I have also provided the code snippets for each technique."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "279d9a4d",
   "metadata": {},
   "source": [
    "#### The techniques are listed below:\n",
    "\n",
    "* Hold Out Cross-validation\n",
    "* K-Fold cross-validation\n",
    "* Stratified K-Fold cross-validation\n",
    "* Leave Pout Cross-validation\n",
    "* Leave One Out Cross-validation\n",
    "* Monte Carlo (Shuffle-Split)\n",
    "* Time Series ( Rolling cross-validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c88bfa7",
   "metadata": {},
   "source": [
    "#### Steps of cross validation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "866af96c",
   "metadata": {},
   "source": [
    "1. Divide data set at random into training and test sets.\n",
    "2. Fit model on training set.\n",
    "3. Test model on test set.\n",
    "4. Compute and save fit statistic using test data (step 3).\n",
    "5. Repeat 1 - 4 several times, then average results of all step 4.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e822e63c",
   "metadata": {},
   "source": [
    "### HoldOut Cross-validation or Train-Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f60424",
   "metadata": {},
   "source": [
    "In this technique of cross-validation, the whole dataset is randomly partitioned into a training set and validation set. Using a rule of thumb nearly 70% of the whole dataset is used as a training set and the remaining 30% is used as the validation set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c555a4c",
   "metadata": {},
   "source": [
    "![title](img/holdout.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "383537cb",
   "metadata": {},
   "source": [
    "#### Pros"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480cdcd3",
   "metadata": {},
   "source": [
    "1. Quick To Execute: As we have to split the dataset into training and validation set just once and the model will be built just once on the training set so gets executed quickly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42280c33",
   "metadata": {},
   "source": [
    "#### Cons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "500d94c2",
   "metadata": {},
   "source": [
    "1. Not Suitable for an imbalanced dataset: Suppose we have an imbalanced dataset that has class ‘0’ and class ‘1’. Let’s say 80% of data belongs to class ‘0’ and the remaining 20% data to class ‘1’. On doing train-test split with train set size as 80% and test data size as 20% of the dataset. It may happen that all 80% data of class ‘0’ may be in the training set and all data of class ‘1’ in the test set. So our model will not generalize well for our test data as it hasn’t seen data of class ‘1’ before.\n",
    "\n",
    "2. A large chunk of data gets deprived of training the model. In the case of a small dataset, a part will be kept aside for testing the model which may have important characteristics which our model may miss out on as it has not trained on that data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "958c4f51",
   "metadata": {},
   "source": [
    "#### Code Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "684142c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "61729c78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of Dataset 150\n"
     ]
    }
   ],
   "source": [
    "iris = load_iris()\n",
    "X = iris.data\n",
    "Y = iris.target\n",
    "print(\"Size of Dataset {}\".format(len(X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad76c220",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression()\n",
    "\n",
    "x_train,x_test,y_train,y_test = train_test_split(X,Y,test_size=0.3,random_state=42)\n",
    "logreg.fit(x_train,y_train)\n",
    "predict=logreg.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7392ab1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score on training set is 0.9619047619047619\n",
      "Accuracy score on test set is 1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy score on training set is {}\".format(accuracy_score(logreg.predict(x_train),y_train)))\n",
    "print(\"Accuracy score on test set is {}\".format(accuracy_score(predict,y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c29165",
   "metadata": {},
   "source": [
    "### K-Fold Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1fd6293",
   "metadata": {},
   "source": [
    "In this technique of K-Fold cross-validation, the whole dataset is partitioned into K parts of equal size. Each partition is called a “Fold“.So as we have K parts we call it K-Folds. One Fold is used as a validation set and the remaining K-1 folds are used as the training set.\n",
    "\n",
    "The technique is repeated K times until each fold is used as a validation set and the remaining folds as the training set.\n",
    "\n",
    "The final accuracy of the model is computed by taking the mean accuracy of the k-models validation data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6c286f",
   "metadata": {},
   "source": [
    "![title](img/k-fold.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f88f5b",
   "metadata": {},
   "source": [
    "#### Pros"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e45812d5",
   "metadata": {},
   "source": [
    "1. The whole dataset is used as both a training set and validation set\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "676bf029",
   "metadata": {},
   "source": [
    "#### Cons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a02f18eb",
   "metadata": {},
   "source": [
    "1. Not to be used for imbalanced datasets: As discussed in the case of HoldOut cross-validation, in the case of K-Fold validation too it may happen that all samples of training set will have no sample form class “1” and only of class “0”.And the validation set will have a sample of class “1”.\n",
    "\n",
    "2. Not suitable for Time Series data: For Time Series data the order of the samples matter. But in K-Fold Cross-Validation, samples are selected in random order.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14253e8b",
   "metadata": {},
   "source": [
    "#### Code Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "72832447",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import cross_val_score,KFold\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c2f0cf25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cubico/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/cubico/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/cubico/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "iris = load_iris()\n",
    "\n",
    "X = iris.data\n",
    "Y = iris.target\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "kf = KFold(n_splits=5)\n",
    "score = cross_val_score(logreg,X,Y,cv=kf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2a184cfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Scores are [1.         1.         0.86666667 0.93333333 0.83333333]\n",
      "Average Cross Validation score :0.9266666666666665\n"
     ]
    }
   ],
   "source": [
    "print(\"Cross Validation Scores are {}\".format(score))\n",
    "print(\"Average Cross Validation score :{}\".format(score.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68336dcd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
