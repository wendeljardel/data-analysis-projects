{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "369bfa60",
   "metadata": {},
   "source": [
    "Cross-validation is a statistical method used to estimate the performance of machine learning models. It is a method for assessing how the results of a statistical analysis will generalize to an independent data set. Cross-validation is a technique for evaluating ML models by training several ML models on subsets of the available input data and evaluating them on the complementary subset of the data. Use cross-validation to detect overfitting, ie, failing to generalize a pattern."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3872d5",
   "metadata": {},
   "source": [
    "#### How does it tackle the problem of overfitting?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46bfe9aa",
   "metadata": {},
   "source": [
    "In Cross-Validation, we use our initial training data to generate multiple mini train-test splits. Use these splits to tune your model. For example in standard k-fold cross-validation, we partition the data into k subsets. Then, we iteratively train the algorithm on k-1 subsets while using the remaining subset as the test set. In this way, we can test our model on completely unseen data. In this notebook, you can read about the 7 most commonly used cross-validation techniques along with their pros and cons. I have also provided the code snippets for each technique."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d48e0f6d",
   "metadata": {},
   "source": [
    "#### The techniques are listed below:\n",
    "\n",
    "* Hold Out Cross-validation\n",
    "* K-Fold cross-validation\n",
    "* Stratified K-Fold cross-validation\n",
    "* Leave Pout Cross-validation\n",
    "* Leave One Out Cross-validation\n",
    "* Monte Carlo (Shuffle-Split)\n",
    "* Time Series ( Rolling cross-validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa457d4",
   "metadata": {},
   "source": [
    "#### Steps of cross validation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7a84cb",
   "metadata": {},
   "source": [
    "1. Divide data set at random into training and test sets.\n",
    "2. Fit model on training set.\n",
    "3. Test model on test set.\n",
    "4. Compute and save fit statistic using test data (step 3).\n",
    "5. Repeat 1 - 4 several times, then average results of all step 4.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f232cf7e",
   "metadata": {},
   "source": [
    "### HoldOut Cross-validation or Train-Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a877d29d",
   "metadata": {},
   "source": [
    "In this technique of cross-validation, the whole dataset is randomly partitioned into a training set and validation set. Using a rule of thumb nearly 70% of the whole dataset is used as a training set and the remaining 30% is used as the validation set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4885f1",
   "metadata": {},
   "source": [
    "![title](img/holdout.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "260887f9",
   "metadata": {},
   "source": [
    "#### Pros"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d1fd666",
   "metadata": {},
   "source": [
    "1. Quick To Execute: As we have to split the dataset into training and validation set just once and the model will be built just once on the training set so gets executed quickly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3321b09",
   "metadata": {},
   "source": [
    "#### Cons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c02fdf69",
   "metadata": {},
   "source": [
    "1. Not Suitable for an imbalanced dataset: Suppose we have an imbalanced dataset that has class ‘0’ and class ‘1’. Let’s say 80% of data belongs to class ‘0’ and the remaining 20% data to class ‘1’. On doing train-test split with train set size as 80% and test data size as 20% of the dataset. It may happen that all 80% data of class ‘0’ may be in the training set and all data of class ‘1’ in the test set. So our model will not generalize well for our test data as it hasn’t seen data of class ‘1’ before.\n",
    "\n",
    "2. A large chunk of data gets deprived of training the model. In the case of a small dataset, a part will be kept aside for testing the model which may have important characteristics which our model may miss out on as it has not trained on that data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92854e9d",
   "metadata": {},
   "source": [
    "#### Code Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eeaeb82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f4908fd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of Dataset 150\n"
     ]
    }
   ],
   "source": [
    "iris = load_iris()\n",
    "X = iris.data\n",
    "Y = iris.target\n",
    "print(\"Size of Dataset {}\".format(len(X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2316ea85",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression()\n",
    "\n",
    "x_train,x_test,y_train,y_test = train_test_split(X,Y,test_size=0.3,random_state=42)\n",
    "logreg.fit(x_train,y_train)\n",
    "predict=logreg.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "38a0293b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score on training set is 0.9619047619047619\n",
      "Accuracy score on test set is 1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy score on training set is {}\".format(accuracy_score(logreg.predict(x_train),y_train)))\n",
    "print(\"Accuracy score on test set is {}\".format(accuracy_score(predict,y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06cd74e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
