{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4df53643",
   "metadata": {},
   "source": [
    "Cross-validation is a statistical method used to estimate the performance of machine learning models. It is a method for assessing how the results of a statistical analysis will generalize to an independent data set. Cross-validation is a technique for evaluating ML models by training several ML models on subsets of the available input data and evaluating them on the complementary subset of the data. Use cross-validation to detect overfitting, ie, failing to generalize a pattern."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5894ef7",
   "metadata": {},
   "source": [
    "#### How does it tackle the problem of overfitting?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb77678f",
   "metadata": {},
   "source": [
    "In Cross-Validation, we use our initial training data to generate multiple mini train-test splits. Use these splits to tune your model. For example in standard k-fold cross-validation, we partition the data into k subsets. Then, we iteratively train the algorithm on k-1 subsets while using the remaining subset as the test set. In this way, we can test our model on completely unseen data. In this notebook, you can read about the 7 most commonly used cross-validation techniques along with their pros and cons. I have also provided the code snippets for each technique."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2da100",
   "metadata": {},
   "source": [
    "#### The techniques are listed below:\n",
    "\n",
    "* Hold Out Cross-validation\n",
    "* K-Fold cross-validation\n",
    "* Stratified K-Fold cross-validation\n",
    "* Leave Pout Cross-validation\n",
    "* Leave One Out Cross-validation\n",
    "* Monte Carlo (Shuffle-Split)\n",
    "* Time Series ( Rolling cross-validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1adbe04d",
   "metadata": {},
   "source": [
    "#### Steps of cross validation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef408839",
   "metadata": {},
   "source": [
    "1. Divide data set at random into training and test sets.\n",
    "2. Fit model on training set.\n",
    "3. Test model on test set.\n",
    "4. Compute and save fit statistic using test data (step 3).\n",
    "5. Repeat 1 - 4 several times, then average results of all step 4.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "609f0965",
   "metadata": {},
   "source": [
    "### HoldOut Cross-validation or Train-Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91824025",
   "metadata": {},
   "source": [
    "In this technique of cross-validation, the whole dataset is randomly partitioned into a training set and validation set. Using a rule of thumb nearly 70% of the whole dataset is used as a training set and the remaining 30% is used as the validation set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9f1a84",
   "metadata": {},
   "source": [
    "![title](img/holdout.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8345419",
   "metadata": {},
   "source": [
    "#### Pros"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6701737",
   "metadata": {},
   "source": [
    "1. Quick To Execute: As we have to split the dataset into training and validation set just once and the model will be built just once on the training set so gets executed quickly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f36dc584",
   "metadata": {},
   "source": [
    "#### Cons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab0a140e",
   "metadata": {},
   "source": [
    "1. Not Suitable for an imbalanced dataset: Suppose we have an imbalanced dataset that has class ‘0’ and class ‘1’. Let’s say 80% of data belongs to class ‘0’ and the remaining 20% data to class ‘1’. On doing train-test split with train set size as 80% and test data size as 20% of the dataset. It may happen that all 80% data of class ‘0’ may be in the training set and all data of class ‘1’ in the test set. So our model will not generalize well for our test data as it hasn’t seen data of class ‘1’ before.\n",
    "\n",
    "2. A large chunk of data gets deprived of training the model. In the case of a small dataset, a part will be kept aside for testing the model which may have important characteristics which our model may miss out on as it has not trained on that data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f040b5",
   "metadata": {},
   "source": [
    "#### Code Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa12a5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd04a2ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of Dataset 150\n"
     ]
    }
   ],
   "source": [
    "iris = load_iris()\n",
    "X = iris.data\n",
    "Y = iris.target\n",
    "print(\"Size of Dataset {}\".format(len(X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fbcbc31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression()\n",
    "\n",
    "x_train,x_test,y_train,y_test = train_test_split(X,Y,test_size=0.3,random_state=42)\n",
    "logreg.fit(x_train,y_train)\n",
    "predict=logreg.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b30e9ad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score on training set is 0.9619047619047619\n",
      "Accuracy score on test set is 1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy score on training set is {}\".format(accuracy_score(logreg.predict(x_train),y_train)))\n",
    "print(\"Accuracy score on test set is {}\".format(accuracy_score(predict,y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ccb4de",
   "metadata": {},
   "source": [
    "### K-Fold Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67ee584",
   "metadata": {},
   "source": [
    "In this technique of K-Fold cross-validation, the whole dataset is partitioned into K parts of equal size. Each partition is called a “Fold“.So as we have K parts we call it K-Folds. One Fold is used as a validation set and the remaining K-1 folds are used as the training set.\n",
    "\n",
    "The technique is repeated K times until each fold is used as a validation set and the remaining folds as the training set.\n",
    "\n",
    "The final accuracy of the model is computed by taking the mean accuracy of the k-models validation data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0280c73",
   "metadata": {},
   "source": [
    "![title](img/k-fold.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0303d2",
   "metadata": {},
   "source": [
    "#### Pros"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8297d6ee",
   "metadata": {},
   "source": [
    "1. The whole dataset is used as both a training set and validation set\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b31d5e6c",
   "metadata": {},
   "source": [
    "#### Cons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5716aa6e",
   "metadata": {},
   "source": [
    "1. Not to be used for imbalanced datasets: As discussed in the case of HoldOut cross-validation, in the case of K-Fold validation too it may happen that all samples of training set will have no sample form class “1” and only of class “0”.And the validation set will have a sample of class “1”.\n",
    "\n",
    "2. Not suitable for Time Series data: For Time Series data the order of the samples matter. But in K-Fold Cross-Validation, samples are selected in random order.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b97851c",
   "metadata": {},
   "source": [
    "#### Code Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4131a54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import cross_val_score,KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3ede9d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "\n",
    "X = iris.data\n",
    "Y = iris.target\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "kf = KFold(n_splits=5)\n",
    "score = cross_val_score(logreg,X,Y,cv=kf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "85888bcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Scores are [1.         1.         0.86666667 0.93333333 0.83333333]\n",
      "Average Cross Validation score :0.9266666666666665\n"
     ]
    }
   ],
   "source": [
    "print(\"Cross Validation Scores are {}\".format(score))\n",
    "print(\"Average Cross Validation score :{}\".format(score.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bce318d",
   "metadata": {},
   "source": [
    "#### Stratified K-Fold Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15cc4b9d",
   "metadata": {},
   "source": [
    "Stratified K-Fold is an enhanced version of K-Fold cross-validation which is mainly used for imbalanced datasets. Just like K-fold, the whole dataset is divided into K-folds of equal size.\n",
    "\n",
    "But in this technique, each fold will have the same ratio of instances of target variable as in the whole datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d028ff",
   "metadata": {},
   "source": [
    "![title](img/stratified.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "769c1f1b",
   "metadata": {},
   "source": [
    "#### Pros"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c065255",
   "metadata": {},
   "source": [
    "1. Works perfectly well for Imbalanced Data: Each fold in stratified cross-validation will have a representation of data of all classes in the same ratio as in the whole dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c9a2dfd",
   "metadata": {},
   "source": [
    "#### Cons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0b1aff7",
   "metadata": {},
   "source": [
    "1. Not suitable for Time Series data: For Time Series data the order of the samples matter. But in Stratified Cross-Validation, samples are selected in random order."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b097165c",
   "metadata": {},
   "source": [
    "#### Code Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "67f9d90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score,StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1d55cbdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "X = iris.data\n",
    "Y = iris.target\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "stratifiedkf = StratifiedKFold(n_splits=5)\n",
    "\n",
    "score = cross_val_score(logreg,X,Y,cv=stratifiedkf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "29a0defd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Scores are [0.96666667 1.         0.93333333 0.96666667 1.        ]\n",
      "Average Cross Validation score :0.9733333333333334\n"
     ]
    }
   ],
   "source": [
    "print(\"Cross Validation Scores are {}\".format(score))\n",
    "print(\"Average Cross Validation score :{}\".format(score.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa474edf",
   "metadata": {},
   "source": [
    "#### Leave P Out cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e6f1608",
   "metadata": {},
   "source": [
    "LeavePOut cross-validation is an exhaustive cross-validation technique, in which p-samples are used as the validation set and remaining n-p samples are used as the training set.\n",
    "\n",
    "Suppose we have 100 samples in the dataset. If we use p=10 then in each iteration 10 values will be used as a validation set and the remaining 90 samples as the training set.\n",
    "\n",
    "This process is repeated till the whole dataset gets divided on the validation set of p-samples and n-p training samples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3240ebb",
   "metadata": {},
   "source": [
    "#### Pros"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2f5343",
   "metadata": {},
   "source": [
    "All the data samples get used as both training and validation samples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7441c064",
   "metadata": {},
   "source": [
    "#### Cons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcfd5dc1",
   "metadata": {},
   "source": [
    "1. High computation time: As the above technique will keep on repeating until all samples get used up as a validation set, it will have higher computational time.\n",
    "\n",
    "2. Not Suitable for Imbalanced dataset: Same as in K-Fold Cross-validation, if in the training set we have samples of only 1 class then our model will not be able to generalize for the validation set.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb00d612",
   "metadata": {},
   "source": [
    "#### Code example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "03923ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import LeavePOut,cross_val_score\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.ensemble import RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fe08025f",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "X = iris.data\n",
    "Y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "21155e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "lpo = LeavePOut(p=2)\n",
    "lpo.get_n_splits(X)\n",
    "\n",
    "tree = RandomForestClassifier(n_estimators=10,max_depth=5,n_jobs=-1)\n",
    "\n",
    "score = cross_val_score(tree,X,Y,cv=lpo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b805a5db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Scores are \n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "Average Cross Validation score :0.9497091722595078\n"
     ]
    }
   ],
   "source": [
    "print(\"Cross Validation Scores are \\n{}\".format(score))\n",
    "print(\"Average Cross Validation score :{}\".format(score.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a84be62",
   "metadata": {},
   "source": [
    "#### Leave One Out cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c46f2e",
   "metadata": {},
   "source": [
    "LeaveOneOut cross-validation is an exhaustive cross-validation technique in which 1 sample point is used as a validation set and the remaining n-1 samples are used as the training set.\n",
    "\n",
    "Suppose we have 100 samples in the dataset. Then in each iteration 1 value will be used as a validation set and the remaining 99 samples as the training set. Thus the process is repeated till every sample of the dataset is used as a validation point.\n",
    "\n",
    "It is the same as LeavePOut cross-validation with p=1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef2b99a",
   "metadata": {},
   "source": [
    "![title](img/one-out.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad5997c",
   "metadata": {},
   "source": [
    "#### Code Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "acd58574",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import LeaveOneOut,cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "db959c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "X = iris.data\n",
    "Y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6beba10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "loo = LeaveOneOut()\n",
    "tree = RandomForestClassifier(n_estimators=10,max_depth=5,n_jobs=-1)\n",
    "score = cross_val_score(tree,X,Y,cv=loo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "eb50f022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Scores are [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1.\n",
      " 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1.]\n",
      "Average Cross Validation score :0.9533333333333334\n"
     ]
    }
   ],
   "source": [
    "print(\"Cross Validation Scores are {}\".format(score))\n",
    "print(\"Average Cross Validation score :{}\".format(score.mean()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a444b2",
   "metadata": {},
   "source": [
    "##### Monte Carlo Cross-Validation(Shuffle Split)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f42d85",
   "metadata": {},
   "source": [
    "Monte Carlo cross-validation, also known as Shuffle Split cross-validation, is a very flexible strategy of cross-validation. In this technique, the datasets get randomly partitioned into training and validation sets.\n",
    "\n",
    "We have decided upon the percentage of the dataset we want to be used as a training set and the percentage to be used as a validation set. If the added percentage of training and validation set size is not sum up to 100 then the remaining dataset is not used in either training or validation set.\n",
    "\n",
    "Let’s say we have 100 samples and 60% of samples to be used as training set and 20% of the sample to be used as validation set then the remaining 20%( 100-(60+20)) is not to be used.\n",
    "\n",
    "This splitting will be repeated ‘n’ times that we have to specify."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f66ba67",
   "metadata": {},
   "source": [
    "![title](img/monte-carlo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90372792",
   "metadata": {},
   "source": [
    "#### Pros"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5510b24c",
   "metadata": {},
   "source": [
    "1. We are free to use the size of the training and validation set.\n",
    "2. We can choose the number of repetitions and not depend on the number of folds for repetitions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31cf548d",
   "metadata": {},
   "source": [
    " #### Cons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6640ed4",
   "metadata": {},
   "source": [
    "1. Few samples may not be selected for either training or validation set.\n",
    "\n",
    "2. Not Suitable for Imbalanced datasets: After we define the size of the training set and validation set, all the samples are randomly selected, so it may happen that the training set may don’t have the class of data that is in the test set, and the model won’t be able to generalize for unseen data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca84424d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
